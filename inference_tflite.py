import os
import argparse
import numpy as np
import tensorflow as tf
from PIL import Image
from tqdm import tqdm


def create_pascal_label_colormap():
    """
    PASCAL VOC ë°ì´í„°ì…‹ì˜ ë¶„í•  ë§ˆìŠ¤í¬ì— ì‚¬ìš©ë˜ëŠ” ê²ƒê³¼ ìœ ì‚¬í•œ ì»¬ëŸ¬ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ ì»¬ëŸ¬ë§µì€ ê° í´ë˜ìŠ¤ IDì— ê³ ìœ í•œ ìƒ‰ìƒì„ ë§¤í•‘í•˜ì—¬ ì‹œê°í™”ë¥¼ ë•ìŠµë‹ˆë‹¤.
    """
    colormap = np.zeros((256, 3), dtype=int)
    ind = np.arange(256, dtype=int)
    for shift in reversed(range(8)):
        for channel in range(3):
            colormap[:, channel] |= ((ind >> channel) & 1) << shift
        ind >>= 3
    return colormap


def label_to_color_image(label):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¼ë²¨(í´ë˜ìŠ¤ ID ë°°ì—´)ì„ ì‚¬ëŒì´ ë³¼ ìˆ˜ ìˆëŠ” ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        label (np.ndarray): 2D ë°°ì—´ í˜•íƒœì˜ í´ë˜ìŠ¤ ID ë§µ.

    Returns:
        np.ndarray: RGB ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ ë°°ì—´.
    """
    if label.ndim != 2:
        raise ValueError(f'labelì€ 2D ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ shape: {label.shape}')
    colormap = create_pascal_label_colormap()
    return colormap[label].astype(np.uint8)


def run_inference(args):
    """
    TFLite ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        args (argparse.Namespace): ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì „ë‹¬ëœ ì¸ì.
    """
    model_path = args.model_path
    input_path = args.input_path
    output_dir = args.output_dir
    save_mode = args.save_mode

    print(f"TFLite ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    try:
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
    except Exception as e:
        print(f"ì˜¤ë¥˜: TFLite ëª¨ë¸ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
        return

    # ëª¨ë¸ì˜ ì…ë ¥ ë° ì¶œë ¥ ì„¸ë¶€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì…ë ¥ ì´ë¯¸ì§€ì˜ ë†’ì´ì™€ ë„ˆë¹„
    _, height, width, _ = input_details['shape']
    print(f"ëª¨ë¸ ì…ë ¥ í¬ê¸°: ({height}, {width})")

    # ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡ ìƒì„±
    image_paths = []
    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp')
    if os.path.isdir(input_path):
        for filename in os.listdir(input_path):
            if filename.lower().endswith(supported_extensions):
                image_paths.append(os.path.join(input_path, filename))
    elif os.path.isfile(input_path) and input_path.lower().endswith(supported_extensions):
        image_paths.append(input_path)

    if not image_paths:
        print(f"ì˜¤ë¥˜: '{input_path}' ê²½ë¡œì—ì„œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    os.makedirs(output_dir, exist_ok=True)
    print(f"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” '{output_dir}'ì— ì €ì¥ë©ë‹ˆë‹¤.")

    # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì…ë ¥ ë°ì´í„° íƒ€ì… ì •ë³´ í•œ ë²ˆë§Œ ì¶œë ¥
    input_type = input_details['dtype']
    print(f"\nğŸ’¡ ì •ë³´: ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ íƒ€ì…ì€ '{np.dtype(input_type).name}' ì…ë‹ˆë‹¤.")

    for image_path in tqdm(image_paths, desc="TFLite ì¶”ë¡  ì§„í–‰ë¥ "):
        try:
            original_image_pil = Image.open(image_path).convert('RGB')
            original_size = original_image_pil.size

            # --- [í•µì‹¬ ìˆ˜ì •] ---
            # í•™ìŠµ/ì–‘ìí™” ê³¼ì •ê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬ ë°©ì‹ì„ ì ìš©í•©ë‹ˆë‹¤.
            # 1. ì´ë¯¸ì§€ë¥¼ TensorFlow í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            image_tensor = tf.convert_to_tensor(original_image_pil, dtype=tf.float32)

            # 2. í•™ìŠµ ë•Œì™€ ë™ì¼í•œ 'BILINEAR' ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
            #    ì´ê²ƒì´ ì–‘ìí™” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²°ì •í•˜ëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤.
            resized_image_tensor = tf.image.resize(
                image_tensor, [height, width], method=tf.image.ResizeMethod.BILINEAR
            )

            # 3. ëª¨ë¸ì˜ ì…ë ¥ íƒ€ì…ì— ë§ê²Œ ë°ì´í„° íƒ€ì…ì„ ë³€í™˜í•˜ê³  ë°°ì¹˜ ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
            if input_type == np.uint8:
                # UINT8 ì–‘ìí™” ëª¨ë¸ì˜ ê²½ìš°
                input_data = tf.cast(resized_image_tensor, tf.uint8)
                input_data = tf.expand_dims(input_data, axis=0)
            else:
                # FLOAT32 ëª¨ë¸ì˜ ê²½ìš° (í•„ìš” ì‹œ ì •ê·œí™”)
                # MobileNet ê³„ì—´ ëª¨ë¸ì€ ë³´í†µ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
                # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì •ê·œí™” ë°©ì‹ì„ ê·¸ëŒ€ë¡œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
                input_data = tf.expand_dims(resized_image_tensor, axis=0)
                # ì˜ˆ: input_data = (input_data / 127.5) - 1.0

            # ì¤€ë¹„ëœ ë°ì´í„°ë¥¼ TFLite ëª¨ë¸ì— ì…ë ¥
            interpreter.set_tensor(input_details['index'], input_data)
            interpreter.invoke()

            # ì¶”ë¡  ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            output_data = interpreter.get_tensor(output_details['index'])

            # í›„ì²˜ë¦¬: ë°°ì¹˜ ì°¨ì› ì œê±° ë° ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            seg_map = np.squeeze(output_data).astype(np.uint8)
            seg_map_pil = Image.fromarray(seg_map)
            resized_seg_map = seg_map_pil.resize(original_size, Image.NEAREST)

            # ì‹œê°í™”ë¥¼ ìœ„í•œ ì»¬ëŸ¬ ë§ˆìŠ¤í¬ ìƒì„± ë° ì˜¤ë²„ë ˆì´
            color_mask_image = label_to_color_image(np.array(resized_seg_map))
            original_image_np = np.array(original_image_pil)
            overlayed_image = (original_image_np * 0.6 + color_mask_image * 0.4).astype(np.uint8)

            # ê²°ê³¼ ì €ì¥
            base_filename = os.path.basename(image_path)
            filename_no_ext, _ = os.path.splitext(base_filename)

            if save_mode in ['comparison', 'all']:
                comparison_image = np.hstack((original_image_np, color_mask_image, overlayed_image))
                comparison_path = os.path.join(output_dir, f"{filename_no_ext}_comparison.png")
                Image.fromarray(comparison_image).save(comparison_path)

            if save_mode in ['overlay', 'all']:
                output_path = os.path.join(output_dir, f"{filename_no_ext}_overlay.png")
                Image.fromarray(overlayed_image).save(output_path)

        except Exception as e:
            print(f"\nì˜¤ë¥˜: '{image_path}' ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            traceback.print_exc()

    print("\n--- ëª¨ë“  ì¶”ë¡  ì™„ë£Œ ---")


def main():
    parser = argparse.ArgumentParser(description="TFLite DeepLabV3+ CBAM ëª¨ë¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸")

    # required=Trueë¥¼ ì œê±°í•˜ê³  default ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    parser.add_argument('--model_path',
                        type=str,
                        default='./exported_models/tflite_models/Model_quant.tflite',
                        help="ì¶”ë¡ ì— ì‚¬ìš©í•  .tflite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.")

    # ë‚˜ë¨¸ì§€ ì¸ìë“¤ì€ required=Trueë¥¼ ìœ ì§€í•˜ê±°ë‚˜ í•„ìš”ì— ë”°ë¼ defaultë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    parser.add_argument('-i', '--input_path', type=str, required=True,
                        help="ì¶”ë¡ í•  ì…ë ¥ ì´ë¯¸ì§€ ë˜ëŠ” í´ë” ê²½ë¡œ")

    # ì¶œë ¥ ê²½ë¡œë„ ì§§ì€ ë³„ëª…ì„ ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.
    parser.add_argument('-o', '--output_dir', type=str, required=True,
                        help="ì¶”ë¡  ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ")


    parser.add_argument(
        '--save_mode',
        type=str,
        default='overlay',
        choices=['overlay', 'comparison', 'all'],
        help="ì¶”ë¡  ê²°ê³¼ ì €ì¥ ë°©ì‹: 'overlay' (ì˜¤ë²„ë ˆì´ ê²°ê³¼ë§Œ), 'comparison' (ì›ë³¸, ë§ˆìŠ¤í¬, ì˜¤ë²„ë ˆì´ ë¹„êµ), 'all' (ëª¨ë‘ ì €ì¥)"
    )
    args = parser.parse_args()

    run_inference(args)


if __name__ == '__main__':
    main()
